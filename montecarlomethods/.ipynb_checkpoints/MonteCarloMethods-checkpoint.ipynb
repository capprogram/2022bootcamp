{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Methods\n",
    "\n",
    "This tutorial will introduce you to Monte Carlo Methods.\n",
    "> _&quot;Monte Carlo methods&quot; is a term covering pretty much any use of pseudo-randomness to help solve any kind of problem._ -- Niall O&#39;Higgins\n",
    "\n",
    "Author: Sheila Kannappan\n",
    "Last Modified: June 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "If you're looking at this notebook, you've presumably already followed these instructions. Please take a moment to complete any that you have not yet finished.\n",
    "\n",
    " * go to https://jupyter.org/try\n",
    " * click \"Try JupyterLab\"\n",
    " * open a terminal in the Lab (File>New>Terminal)\n",
    " * paste the following into the terminal to get the jupyter notebook:<br/>\n",
    "  `wget https://raw.githubusercontent.com/capprogram/2021bootcamp/master/montecarlomethods/MonteCarloMethods.ipynb?token=ACPDL67MPAJGQB5LA7NJSILAYFFJU -O /home/jovyan/demo/MonteCarloMethods.ipynb`\n",
    " * paste all of the following into the terminal to get the individual python codes:<br/>\n",
    "  `wget https://raw.githubusercontent.com/capprogram/2021bootcamp/master/montecarlomethods/partI_2.py.solns -O /home/jovyan/demo/partI_2.py.solns` <br>\n",
    "  `wget https://raw.githubusercontent.com/capprogram/2021bootcamp/master/montecarlomethods/partI_3.py.solns -O /home/jovyan/demo/partI_3.py.solns` <br>\n",
    "  `wget https://raw.githubusercontent.com/capprogram/2021bootcamp/master/montecarlomethods/partI_4.py.solns -O /home/jovyan/demo/partI_4.py.solns` <br>\n",
    "  `wget https://raw.githubusercontent.com/capprogram/2021bootcamp/master/montecarlomethods/partII_2.py.solns -O /home/jovyan/demo/partII_2.py.solns` <br>\n",
    "  `wget https://raw.githubusercontent.com/capprogram/2021bootcamp/master/montecarlomethods/partIII_1.py.solns -O /home/jovyan/demo/partIII_1.py.solns` <br>\n",
    "  `wget https://raw.githubusercontent.com/capprogram/2021bootcamp/master/montecarlomethods/partIII_2.py.solns -O /home/jovyan/demo/partIII_2.py.solns` <br>\n",
    " * if necessary, click the refresh page (curled arrow) at the top of the webpage\n",
    " * launch the jupyter notebook by double clicking on it\n",
    " * you can run or re-run individual cells in the notebook by clicking on them and typing Ctrl-Enter\n",
    " * you can edit individual python codes outside the notebook by double clicking on them in the list of files on the left side of the jupyter lab window, then editing them in the window that pops up and saving with Ctrl-s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .py files transferred above contain partial answers to the exercises below, left incomplete for you to finish. Select exercises have solutions as detailed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Random Number Generators\n",
    "\n",
    "There are two ways to generate random numbers:\n",
    "\n",
    "- physical measurements that are expected to be random (e.g., coin flips)\n",
    "- computational algorithms that produce long sequences of apparently random results, in fact completely determined by an initial &quot;seed&quot; value\n",
    "\n",
    "The latter are often called _pseudo-random_ number generators.\n",
    "\n",
    "Look over the description of the &quot;random&quot; package for python here: [https://docs.python.org/3/library/random.html](https://docs.python.org/3/library/random.html)\n",
    "\n",
    "Check out the Mersenne Twister on the internet -- it&#39;s not an amusement park ride!\n",
    "\n",
    "**Exercise 1:** Use _random.random_ to generate a variable x consisting of 10 random numbers between 0 and 1. Repeat to create a second random variable y, and plot x and y against each other. Verify that there is no correlation.\n",
    "\n",
    "NOTE: The command `plt.show()` is sometimes needed for plots to show up visibly; if you have properly updated Anaconda the default should be that you don't need it, but if no plots are appearing, try adding it to the end of your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xx=[] # variable named xx to avoid single-letter variable name\n",
    "yy=[]\n",
    "\n",
    "for i in range(0,10):\n",
    "   xx.append(random.random())\n",
    "\n",
    "# insert code to get yy here\n",
    "\n",
    "# uncomment the code below to make the plot\n",
    "#plt.plot(xx,yy,'g*')\n",
    "#plt.xlabel('x')\n",
    "#plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that random.random samples from a _uniform_ distribution from 0 to 1 by default. <br>\n",
    "\n",
    "**Exercise 2:** Now use the _random.seed_ command -- for example, `random.seed(555)` -- to control the random numbers in x and y such that they are identical. Plot x and y against each other and verify that there is now a perfect correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy code from previous code block as a starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `append` command you have used up to now is a slow and inefficient way to build up a set of numbers. _Recall that the python package &quot;numpy&quot; enables array math._ For example, we could have computed `xx` like so: <br>\n",
    "\n",
    "    import numpy.random as npr\n",
    "    rngx = npr.default_rng()\n",
    "    xx = rngx.uniform(size=10)\n",
    "\n",
    "Visit the [numpy.random webpage](https://numpy.org/doc/stable/reference/random/index.html) to read about it a bit, then import numpy.random and use it to rewrite your code above. You can compare to the solutions in partI_2.py.solns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as npr\n",
    "\n",
    "#generate 10-element random xx and yy here\n",
    "\n",
    "#plt.plot(xx,yy,'g*')\n",
    "#plt.xlabel('x')\n",
    "#plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Random Numbers\n",
    "\n",
    "The Gaussian or Normal distribution is the most commonly used model for random uncertainties (non-systematic errors/noise) in data. It has the form <img src=\"https://latex.codecogs.com/png.latex?\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp{\\left(-\\frac{u^2}{2\\sigma^2}&space;\\right&space;)}\" />\n",
    "\n",
    "Graphically, this form looks like <br>\n",
    "<img src=\"https://github.com/capprogram/2017bootcamp-general/raw/master/MonteCarloTutorial/gaussianconfidenceintervals.png\"/>\n",
    "\n",
    "We can use the Gaussian distribution to describe our confidence in a specific value (how much the value might vary, often expressed as a plus-or-minus error bar) or our confidence that a given detected signal is not just noise (how far the value rises above baseline noise):\n",
    "\n",
    "1. The error bars on data values are typically set to equal the expected &plusmn;1&sigma; variations from random measurement errors or inherent noise _(caveat: some research fields use &plusmn;2&sigma; error bars)_. Different possible error bar ranges are referred to as &quot;confidence intervals.&quot;. From the diagram, &plusmn;1&sigma; corresponds to a &quot;68% confidence interval.&quot;.\n",
    "\n",
    "2. The signal-to-noise (S/N) ratios for data values representing &quot;detections&quot; are typically given in terms of the background noise (i.e., S/N=3 means S=3&sigma; (caveat: if the signal is extended in time/space/&lambda;/etc., it is really a sum of several data points and you must use error propagation rules). From the diagram, we see a S/N&gt;3 \"detection\" has only 0.1% probability of occurring by chance, so people generally say a measurement at S/N=3 is detected &quot;at 99.9% confidence.&quot; (Strictly speaking this language is misleading; see reading on the p-value crisis in the Boot Camp wiki.)\n",
    "\n",
    "**Exercise 3:** Use the _normal_ (as opposed to _uniform_) method of `npr.default_range` to generate a variable u (u for &quot;uncertainty&quot;) consisting of 1000 random numbers with mean zero and standard deviation &sigma; = 1. Create a histogram of the values to verify that they look like a Gaussian distribution. Compute the functional form of the Gaussian and overplot it to see how well it matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "mean, sigma = 0., 1.\n",
    "rngu = npr.default_rng()\n",
    "#uu = rngu.normal(???) # look up the correct syntax in the numpy.random.default_rng documentation\n",
    "\n",
    "# plot histogram\n",
    "# histogram plotting methods taken from http://matplotlib.org\n",
    "#n1, bins1, patches1 = plt.hist(uu,bins=50,density=True,histtype='stepfilled')\n",
    "#plt.setp(patches1,'facecolor','g','alpha',0.75) # optional if you wish to change histogram appearance\n",
    "\n",
    "# overplot expected Gaussian distribution on top of histogram using bins1 as u values-- you will need np.exp and np.sqrt\n",
    "#gaussfunct=??  # fill in using equation where input values are histogram bin locations \"bins1\"\n",
    "#plt.plot(bins1,gaussfunct,'k--',linewidth=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare to the solutions in partI_3.py.solns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** Use `numpy.where` to determine what percentage of the time the variable u lies inside &plusmn;1&sigma; or &plusmn;2&sigma;. If you plot a set of data points with error bars equal to u, how often should a line you fit to the data actually go through the error bars of a given point (assuming the model is correct)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting with uu from previous cell, generated with sigma = 1\n",
    "limval= 1. # set to 1 or 2\n",
    "#fractinrange = ???/np.size(uu) # denominator is total number of uu values, what should numerator be?\n",
    "#print(fractinrange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare to the solutions in partI_4.py.solns.\n",
    "\n",
    "If the model is correct and the error bars represent 68% confidence intervals (&plusmn;1&sigma;), then for a given point, the probability of the line going through the error bars is 68%.  You can tell by eye that something is wrong (bad model, too large/small error bars, etc.) if the fitted line goes through many more or fewer than 68% of the data points' error bars. (Caveat: very rarely, &plusmn;2&sigma; error bars may be shown.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Areas or Volumes of Enclosed Regions\n",
    "\n",
    "A basic application of random number generation is in measuring the areas or volumes of enclosed regions, especially non-rectangular regions for which a direct measurement would be difficult. The method is to choose points randomly in a rectangular region enclosing the region of interest, then find the fraction of the points that land inside the region of interest in order to assess its subarea/subvolume.\n",
    "\n",
    "**Exercise 1:** Use _random.uniform_ to measure the area of a circle with radius 1 and thus to measure the value of &pi;. How many darts do you need to get a good, consistent estimate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study and run the code in this cell to complete exercise 1\n",
    "# (adapted from http://niallohiggins.com/2007/07/05/monte-carlo-simulation-in-python-1/)\n",
    "\n",
    "import random # not using numpy for simplicity\n",
    "\n",
    "DARTS=1000\n",
    "hits = 0\n",
    "throws = 0\n",
    "for i in range (0, DARTS):\n",
    "    throws += 1\n",
    "    xx = random.uniform(-1,1) # square box circumscribes circle with radius 1\n",
    "    yy = random.uniform(-1,1)\n",
    "    distsquared = xx**2 + yy**2 # taking the square root here would slow down the code\n",
    "    if distsquared <= 1.0:\n",
    "        hits = hits + 1.0\n",
    "\n",
    "# hits / throws = area of circle / area of square = Pi 1^2 / 2^2\n",
    "estpi = 4 * (hits / throws)\n",
    "\n",
    "print(\"pi = %s\" % estpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Use numpy&#39;s array version of random to measure the area under a Gaussian from -1&sigma; to +1&sigma;. Think about why this area is equal to the percentage of u values between &plusmn;1&sigma;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the code in this cell to complete exercise 2\n",
    "# hint: you can get the equation for a Gaussian from part I, exercise 3\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "sigma=1.\n",
    "throws=100 # play with this number -- how many darts are enough?\n",
    "\n",
    "# throw darts in a box circumscribing the portion of the Gaussian that is of interest\n",
    "\n",
    "# width is from -sigma to +sigma\n",
    "rngx = npr.default_rng()\n",
    "xvals=(rngx.uniform(size=throws) * 2.*sigma - 1.*sigma) # what is the range of xvals if uniform goes from 0 to 1?\n",
    "\n",
    "# height is from 0 to peak value of Gaussian\n",
    "rngy = npr.default_rng()\n",
    "#yvals=(rngy.uniform(size=throws) * ??? # how should you renormalize uniform so 0 to 1 maps to 0 to peak?\n",
    "\n",
    "# determine the boundary of the desired region as a function of x values\n",
    "#gaussfunct=??? fill in as a function of xvals\n",
    "\n",
    "# count the number of hits\n",
    "#hits=np.size(np.where(yvals <= gaussfunct))\n",
    "\n",
    "# compute area = (hits/throws) * rectangle area\n",
    "#rectarea = ??? # fill in based on width and height determined above\n",
    "#area = (hits/throws)*rectarea\n",
    "\n",
    "#print(\"area is %s\" % area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare to the solutions in partII_2.py.solns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Random Selection from a Non-Uniform Distribution\n",
    "\n",
    "It may happen that you want to select random numbers from a distribution of your own. For example, suppose we want the distribution of radius values for a set of points drawn randomly from within a circle as shown below.\n",
    "\n",
    "The probability of a point having a given radius increases with the area of the annulus that that radius lies in, so <img src=\"https://latex.codecogs.com/png.latex?\\inline&space;p(r)dr=\\frac{2\\pi&space;rdr}{\\pi&space;R^2}\" />where R is the radius of the circle. (Note that the integral <img src=\"https://latex.codecogs.com/png.latex?\\inline&space;\\int_0^Rp(r)dr=1\" /> as is required for a probability distribution.) The trick to computing the (non-uniform) probability distribution for _r_ is to map random values _x_ drawn from a uniform distribution [0, 1) onto values of _r_ in such a way that the correct frequency of r values is produced. A one-to-one mapping in which the _integrated_ probability out to _r_ in [0, R) is equal to the integrated probability out to _x_ in [0, 1) does the trick. In &quot;inverse transform sampling,&quot; we first generate values using a uniform random number generator, then map them to values drawn from another probability distribution using this type of integral mapping.\n",
    "\n",
    "<img src=\"https://github.com/capprogram/2017bootcamp-general/raw/master/MonteCarloTutorial/randomdotsincircle.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** First, use the _uniform_ method of `numpy.random.default_rng` to select radii randomly in a circle with radius R=1 by inverse transform sampling. You will need to solve analytically for the radius within the circle r that yields a given value of the integral <img src=\"https://latex.codecogs.com/png.latex?\\inline&space;\\int_0^rp(r)dr\" /><br>\n",
    "Second, compare the distribution of radii selected by this method to the distribution of radii obtained by selecting &quot;hits&quot; in a circle as in Exercise 1 from Part II. (Note: this second task requires that you generate a new block of code, not just tweak the code provided. You should try to find bits of earlier code that you can copy/imitate/modify to make an array of radii, then plot the new radii in a histogram on top of the histogram from inverse transform sampling.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit and run the code in this cell to complete exercise 1\n",
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# notes: radial probability distribution, its integral, and its reverse lookup\n",
    "#### next 3 lines are pseudo-code, do not uncomment but use for reference\n",
    "#### p_r=2.*3.14159*r / (3.14159*R**2)\n",
    "#### intp_r=3.14159*r**2 / (3.14159*R**2)  =  r**2 for R=1\n",
    "#### r_at_given_intp_r= ??? solve analytically to find r\n",
    "\n",
    "# choose nran random numbers in uniform interval 0-1\n",
    "nran = 1000\n",
    "rngx = npr.default_rng()\n",
    "xvals = rngx.uniform(size=nran)\n",
    "\n",
    "# compute the integrated area under the uniform distribution p_u: integral from 0 to x of (p_u*dx) = integral(1*dx) = x\n",
    "intp_uni = xvals # rename variable for clarity that we have done the integral\n",
    "\n",
    "# solve for the radii that give the same integrated area under p_r as the randomly chosen xvals\n",
    "intp_r = intp_uni # set desired integrated area equal to that from uniform distribution\n",
    "#radvals = ??? # compute radii from intp_r using analytic solution you found above\n",
    "\n",
    "# make a histogram\n",
    "#n1, bins1, patches1 = plt.hist(radvals,bins=50,density=1,histtype='stepfilled')\n",
    "#plt.setp(patches1,'facecolor','g','alpha',0.75)\n",
    "\n",
    "# add code below to compare with radii chosen by throwing darts (see part II exercise 1 for a starting point)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare to the solutions in partIII_1.py.solns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise 2:** Use the _uniform_ method of `numpy.random.default_rng` to select values from a Gaussian distribution using inverse transform sampling. In this exercise you are essentially recreating the _normal_ method of `numpy.random.default_rng` (presumably with inferior optimization) -- the random number generator \"under the hood\" is always drawing from a uniform distribution. <br><br>\n",
    "Hint: the integral of a Gaussian function that is centered on 0 over the range from -infinity to u is:\n",
    "\n",
    "<img src=\"https://latex.codecogs.com/png.latex?\\int_{-\\infty}^u\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp{\\left(-\\frac{u^2}{2\\sigma^2}\\right)}du=0.5+0.5&space;erf(u/\\sqrt{2})\" />\n",
    "\n",
    "You can import &quot;erf&quot; (the error function) from scipy.special."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit and run the code in this cell to complete exercise 2\n",
    "\n",
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "from scipy.special import erf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# notes: probability distribution, its integral, and its reverse lookup\n",
    "#### next 3 lines are pseudo-code, do not uncomment but use for reference\n",
    "#### p_g=exp((-1.*u**2)/(2.*sigma**2))/(sigma*sqrt(2.*3.14159))\n",
    "#### intp_g=0.5+0.5*erf(u/sqrt(2.))\n",
    "#### u_at_given_intp_g= ??? can't solve analytically, must create lookup table\n",
    "\n",
    "# choose nran random numbers in uniform interval 0-1\n",
    "nran = 1000\n",
    "rngx = npr.default_rng()\n",
    "xvals = rngx.uniform(size=nran)\n",
    "\n",
    "# the integral of uniform distribution p_u*dx (=1*dx) from 0 to x is just x\n",
    "intp_uni = xvals # rename variable for clarity that we have done the integral\n",
    "\n",
    "# solve for the u values that give the same integrated area under p_g as the randomly chosen xvals\n",
    "#intp_g = intp_uni # set desired integrated area equal to that from uniform distribution\n",
    "#lookupuvals = (np.array([range(0,10000)])-5000)/1000. \n",
    "#lookupintvals = ??? # fill in integral of p_g evaluated at lookupuvals\n",
    "#uvals = np.zeros(nran) # creating uvals array with size equal to number of random values, =0 as placeholder\n",
    "#for i in range(0,nran):\n",
    "#    diffs = abs(lookupintvals-intp_g[i])\n",
    "#    uvals[i] = lookupuvals[np.where(diffs == diffs.min())] # filling in each element of uvals with closest lookup value\n",
    "\n",
    "# make a histogram\n",
    "#n1, bins1, patches1 = plt.hist(uvals,bins=50,density=1,histtype='stepfilled')\n",
    "#plt.setp(patches1,'facecolor','g','alpha',0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare to the solutions in partIII_2.py.solns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. For Further Inquiry\n",
    "\n",
    "Random number generation is useful in many contexts. For example, you may wish to generate mock data sets with realistic scatter to test algorithms. Simulated data play an important role in planning and testing experiments.\n",
    "\n",
    "[http://www.ligo.org/news/blind-injection.php](http://www.ligo.org/news/blind-injection.php)\n",
    "\n",
    "Another technique that relies on Monte Carlo methods is &quot;bootstrapping,&quot; actually a family of techniques all of which use random resampling of a real data set to estimate the uncertainties on parameters or model fits characterizing that data set. We'll return to bootstrapping in another tutorial.\n",
    "\n",
    "[http://en.wikipedia.org/wiki/Bootstrapping\\_%28statistics%29](http://en.wikipedia.org/wiki/Bootstrapping_%28statistics%29)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
